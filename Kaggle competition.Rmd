---
title: "STATS415"
author: "Haichen Fu"
date: "3/18/2022"
output: pdf_document
---
Notes:
Outcomes (y) are synthetic - they were generated from a subset of size k â‰ª p variables.
y is a nonlinear function of the k variables with interactions

Ideas: 
Use CV to tune on training set
Use Lasso to select variables to use in other, more flexible, models Use principal components as input to other regression models (including non-linear and tree-based models)

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
# Libraries
library(haven)
library(tidyverse)
```

```{r}
# Combining datasets
bm_09       <- read_xpt("2009_BMX_F.XPT")
bp_09       <- read_xpt("2009_BPX_F.XPT")
demo_09     <- read_xpt("2009_DEMO_F.XPT")
dr_09       <- read_xpt("2009_DR1TOT_F.XPT")
smq_09      <- read_xpt("2009_SMQ_F.XPT")
tchol_09    <- read_xpt("2009_TCHOL_F.XPT")

bm_11       <- read_xpt("2011_BMX_G.XPT")
bp_11       <- read_xpt("2011_BPX_G.XPT")
demo_11     <- read_xpt("2011_DEMO_G.XPT")
dr_11       <- read_xpt("2011_DR1TOT_G.XPT")
smq_11      <- read_xpt("2011_SMQ_G.XPT")
tchol_11    <- read_xpt("2011_TCHOL_G.XPT")

bm_13       <- read_xpt("2013_BMX_H.XPT")
bp_13       <- read_xpt("2013_BPX_H.XPT")
demo_13     <- read_xpt("2013_DEMO_H.XPT")
dr_13       <- read_xpt("2013_DR1TOT_H.XPT")
smq_13      <- read_xpt("2013_SMQ_H.XPT")
tchol_13    <- read_xpt("2013_TCHOL_H.XPT")

bm_15       <- read_xpt("2015_BMX_I.XPT")
bp_15       <- read_xpt("2015_BPX_I.XPT")
demo_15     <- read_xpt("2015_DEMO_I.XPT")
dr_15       <- read_xpt("2015_DR1TOT_I.XPT")
smq_15      <- read_xpt("2015_SMQ_I.XPT")
tchol_15    <- read_xpt("2015_TCHOL_I.XPT")

bm_17       <- read_xpt("2017_BMX_J.XPT")
bp_17       <- read_xpt("2017_BPX_J.XPT")
demo_17     <- read_xpt("2017_DEMO_J.XPT")
dr_17       <- read_xpt("2017_DR1TOT_J.XPT")
smq_17      <- read_xpt("2017_SMQ_J.XPT")
tchol_17    <- read_xpt("2017_TCHOL_J.XPT")


df_list_2009 <- list(bm_09, bp_09, demo_09, dr_09, smq_09, tchol_09)
df_list_2011 <- list(bm_11, bp_11, demo_11, dr_11, smq_11, tchol_11)
df_list_2013 <- list(bm_13, bp_13, demo_13, dr_13, smq_13, tchol_13)
df_list_2015 <- list(bm_15, bp_15, demo_15, dr_15, smq_15, tchol_15)
df_list_2017 <- list(bm_17, bp_17, demo_17, dr_17, smq_17, tchol_17)


df_2009 <- df_list_2009 %>% reduce(full_join, by='SEQN')
df_2011 <- df_list_2011 %>% reduce(full_join, by='SEQN')
df_2013 <- df_list_2013 %>% reduce(full_join, by='SEQN')
df_2015 <- df_list_2015 %>% reduce(full_join, by='SEQN')
df_2017 <- df_list_2017 %>% reduce(full_join, by='SEQN')

full_df <- bind_rows(df_2009, df_2011, df_2013, df_2015, df_2017)
head(full_df)
```
## Training set
```{r}
#combine training data with the full set
train<-read.csv("train.csv")
train_df<-merge(x=train,y=full_df,all.x=TRUE,by="SEQN")
```

```{r}
#drop out all columns containing NA
dropna<-vector()
for (i in colnames(train_df)){
  col<-train_df[,which(colnames(train_df)==i)]
  if(sum(is.na(col))>0){
    dropna<-cbind(dropna,i)
  }
}
train_df<-train_df[,-which(colnames(train_df) %in% dropna)]
```

```{r}
#drop out columns specified by the guidance 
drop<-list("SMDUPCA","SMD100BR","DR1DRSTZ","DRABF","RIDSTATR")
train_df<-train_df[,-which(colnames(train_df) %in% drop)]
```

```{r}
#standardize all variables
standardize<-function(x){
  return((x-mean(x))/sd(x))
}
train_std<-as.data.frame(lapply(train_df[,-2],standardize))
train_std$y<-train_df$y                
```

## Testing set
```{r}
#combine test set with the full set
test<-read.csv("test.csv")
test_df<-merge(x=test,y=full_df,all.x=TRUE,by="SEQN")
test_df<-test_df[,-which(colnames(test_df) %in% dropna)]
test_df<-test_df[,-which(colnames(test_df) %in% drop)]

#standardize test set
test_std<-as.data.frame(lapply(test_df,standardize))
```

# Split into training and validation set
```{r}
set.seed(1)
trainid<-sample(nrow(train_std),trunc(nrow(train_std)*0.8))
train_model<-train_std[trainid,]
test_model<-train_std[-trainid,]
```

## Notes
train_df: training set including all variables
test_df: test set including all variables with y to be predicted
train_std: standardized training set
test_std: standardized test set with y to be predicted
train_model: 80% split training set used to train
test_model: 20% validation set
lasso_coef: variables selected by lasso

## Models

```{r}
#linear regression model

lg<-lm(y~.,data=train_model)
lg_train_pred<-predict(lg,train_model)
lg_test_pred<-predict(lg,test_model)
test_response<-test_model$y
(cor(lg_train_pred,train_model$y))^2
(cor(lg_test_pred,test_response))^2
```
## Variable selection
```{r}
#lasso select variable
library(glmnet)
#no need to transform variables to dummy in this case as all predictors are quantitative
trainX<-model.matrix(y~.,train_model)[,-1]
trainY<-train_model$y
testX<-model.matrix(y~.,test_model)[,-1]
testY<-test_model$y

#fit lasso model with cross validation to select the best lambda
fitlasso<-glmnet(trainX,trainY,alpha=1,standardize = FALSE)
set.seed(123)
cv<-cv.glmnet(trainX,trainY,alpha=1,standardize=FALSE)
bestlam<-cv$lambda.min
bestlam

#training error
lasso_pred_train<-predict(fitlasso,s=bestlam,newx=trainX)
trainerror_lasso<-mean((lasso_pred_train-trainY)^2)
(cor(lasso_pred_train,train_model$y))^2

#test error
lasso_pred_test<-predict(fitlasso,s=bestlam,newx=testX)
testerror_lasso<-mean((lasso_pred_test-testY)^2)
(cor(lasso_pred_test,test_model$y))^2
```
```{r}
#coefficients selected by lasso
lasso_coef<-coef(fitlasso,s=bestlam)
lasso_coef<-as.data.frame(lasso_coef[,1])
lasso_coef$name<-c("Intercept",colnames(train_model[,-144]))
lasso_coef<-lasso_coef$name[which(lasso_coef$`lasso_coef[, 1]`!=0)]
lasso_coef<-lasso_coef[-1] #remove intercept
length(lasso_coef)
```

```{r}
#PCR regression
library(pls)
set.seed(1)
pcr.fit<-pcr(y~.data=train_model,scale=TRUE,validation="CV")
cverr<-RMSEP(pcr.fit)$val[1,,]
which.min(cverr)-1

#PLS
set.seed(1)

pls.fit<-plsr(y~.,data=train_model,scale=TRUE,validation="CV")
```


```{r}
#KNN (using variables selected by lasso)
library(FNN)
lasso_coef
knn_train<-train_model[,lasso_coef]
knn_test<-test_model[,lasso_coef]


#select K by cross validation
Ks<-seq(1,101,by=5)
test_R2s<-c()
for(K in Ks){
  knnmodel<-knn.reg(train=knn_train,y=train_model$y,test=knn_test,k=K)
  test_R2<-cor(knnmodel$pred,test_model$y)^2
  test_R2s<-c(test_R2s,test_R2)
}
```
```{r}
test_R2s
Ks[which.max(test_R2s)]
max(test_R2s)
```



```{r}
#Decision tree
library(tree)
tree_model<-tree(y~.,data=train_model)
cv.train<-cv.tree(tree_model)
tree_pred<-predict(tree_model,newdata=test_model)
```

```{r}
(cor(tree_pred,test_model$y))^2
```

```{r}
#Random forest
library(randomForest)
#rf_model<-randomForest(y~.,data=train_model,mtry=8,importance=TRUE)
#rf_test_pred<-predict(rf_model,newdata=test_model)
#(cor(rf_test_pred,test_model$y))^2


Ms<-seq(1,31,by=3)
test_rf_R2s<-c()
for(m in Ms){
  rf_model<-randomForest(y~.,data=train_model,mtry=m,importance=TRUE)
  rf_test_pred<-predict(rf_model,newdata=test_model)
  test_rf_R2<-cor(rf_test_pred,test_model$y)^2
  test_rf_R2s<-c(test_rf_R2s,test_rf_R2)
}
```

```{r}
#20220327_random forest submission
rf_truetest_pred<-predict(rf_model,newdata=test_std)
test$y<-rf_truetest_pred
test
write.csv(test,file="rf_model.csv",row.names=FALSE)
```
### To be answer:
 * variable selection & How to include intersection terms into the model? 
  It seems that the lasso model still retain too many variables: )
 * how to use principal components to train and make prediction for test set? 
